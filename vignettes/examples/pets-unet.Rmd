---
title: "UNET implementation"
desc: "Implements a UNET model to separate the background of images of cats and dogs."
category: 'intermediate'
---

```{r, eval = FALSE}
# Packages ----------------------------------------------------------------
library(torch)
library(torchvision)
library(torchdatasets)
library(luz)

# Datasets and loaders ----------------------------------------------------

dir <- "~/Downloads/" #caching directory

# A light wrapper around the `oxford_pet_dataset` that resizes and transforms 
# input images and masks to the specified `size` and introduces the `augmentation`
# argument, allowing us to specify transformations that must be synced between 
# images and masks, eg. flipping, cropping, etc.
pet_dataset <- torch::dataset(
  inherit = oxford_pet_dataset,
  initialize = function(..., augmentation = NULL, size = c(224, 224)) {
    
    input_transform <- function(x) {
      x %>% 
        transform_to_tensor() %>% 
        transform_resize(size)
    }
    
    target_transform <- function(x) {
      x <- torch_tensor(x, dtype = torch_long())
      x <- x[newaxis,..]
      transform_resize(x, size, interpolation = 0)
    }
    
    self$split <- split
    super$initialize(
      ..., 
      transform = input_transform,
      target_transform = target_transform
    )
    
    if (is.null(augmentation))
      self$augmentation <- function(...) {list(...)}
    else
      self$augmentation <- augmentation
    
  },
  .getitem = function(i) {
    items <- super$.getitem(i)
    do.call(self$augmentation, items)
  }
)

train_ds <- pet_dataset(
  dir,
  download = TRUE,
  split = "train"
)

valid_ds <- oxford_pet_dataset(
  dir,
  download = TRUE,
  split = "valid"
)


train_dl <- dataloader(train_ds, batch_size = 128, shuffle = TRUE)
valid_dl <- dataloader(valid_ds, batch_size = 128)

x <- coro::collect(train_dl, 1)

# Define the network ------------------------------------------------------

# We use a pre-trained mobile net encoder. we take intermediate features of
# mobilenet.
encoder <- torch::nn_module(
  initialize = function(x) {
    model <- model_mobilenet_v2(pretrained = TRUE)
    self$stages <- nn_module_list(list(
      nn_identity(),
      # TODO: this can be improved once we implement subset for `nn_sequential`
      # see https://github.com/mlverse/torch/issues/675
      nn_sequential(!!!lapply(1:2, function(x) model$features[[x]])),
      nn_sequential(!!!lapply(3:4, function(x) model$features[[x]])),
      nn_sequential(!!!lapply(5:7, function(x) model$features[[x]])),
      nn_sequential(!!!lapply(8:14, function(x) model$features[[x]])),
      nn_sequential(!!!lapply(15:18, function(x) model$features[[x]]))
    ))
    
    for (par in self$parameters) {
      par$requires_grad_(FALSE)
    }
    
  },
  forward = function(x) {
    features <- list()
    for (i in 1:length(self$stages)) {
      x <- self$stages[[i]](x)
      features[[length(features) + 1]] <- x
    }
    features
  }
)


fitted <- triplet_model %>%
  setup(optimizer = optim_adam) %>%
  set_hparams(embedding_dim = 2) %>%
  fit(train_dl, epochs = 10, valid_data = test_dl)

# Serializing

luz_save(fitted, "triplet.pt")

```

